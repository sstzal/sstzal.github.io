<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Shuai Shen</title>
  
  <meta name="author" content="Shuai Shen">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Shuai Shen</name>
              </p>
              <p>I am a fourth year Ph.D. student in the Department of Automation at Tsinghua University, advised by Prof. <a href="http://ivg.au.tsinghua.edu.cn/Jiwen_Lu/">Jiwen Lu</a>. 
			  </p>
			  <p>In 2019, I received my B.S. degree in the Department of Automation at Tsinghua University.
              </p>
              <p>My research interests lie in computer vision and deep learning, particularly face clustering and face generation.
              </p>
              <p style="text-align:center">
                <a href="mailto:shens19@mails.tsinghua.edu.cn"> Email </a> &nbsp/&nbsp  
                <a href="https://github.com/sstzal"> GitHub </a> 
              </p>
            </td>
            <td style="padding:2.5%;width:30%;max-width:30%">
              <a href="images/shenshuai1.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/shenshuai_circle.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
		
		
		<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>News</heading>
            <p>
	      <li style="margin: 5px;">
                <b>2023-10:</b> I get the Friends of Tsinghua - Suzhou Talent Scholarship(top 5%)</a>.
              </li>
	      <li style="margin: 5px;">
                <b>2023-08:</b> One paper is accepted to <a href="https://signalprocessingsociety.org/publications-resources/ieee-transactions-multimedia">TPAMI</a>.
              </li>
	      <li style="margin: 5px;">
                <b>2023-07:</b> One paper is accepted to <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">TPAMI</a>.
              </li>
	      <li style="margin: 5px;">
                <b>2023-07:</b> One paper is accepted to <a href="https://iccv2023.thecvf.com/">ICCV 2023</a>.
              </li>
	      <li style="margin: 5px;">
                <b>2023-03:</b> One paper is accepted to <a href="http://cvpr2023.thecvf.com/">CVPR 2023</a>.
              </li>
	      <li style="margin: 5px;">
                <b>2022-10:</b> I get the Huiyan Talent Second Prize Scholarship of Tsinghua (top 10%)</a>.
              </li>
	      <li style="margin: 5px;">
                <b>2022-07:</b> One paper is accepted to <a href="https://eccv2022.ecva.net/">ECCV 2022</a>.
              </li> 
	      <li style="margin: 5px;">
                <b>2021-03:</b> One paper on is accepted to <a href="http://cvpr2021.thecvf.com/">CVPR 2021</a>.
              </li>
            </p>
          </td>
        </tr>
      </tbody></table>
	  
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Selected Publications</heading>
			  <p></p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


	<tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/star++.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>STAR-FC: Structure-Aware Face Clustering on Ultra-Large-Scale Graphs</papertitle>
              <br>
			  <strong>Shuai Shen</strong>, Wanhua Li, Zheng Zhu, Jie Zhou, and Jiwen Lu
              <br>
              <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</em>, 2023
			  <br>
              <a href="https://ieeexplore.ieee.org/abstract/document/10195951">[PDF]</a> 
              <a href="https://github.com/sstzal/STAR-FC">[Code]</a>
              <br>
              <p> A NeRF-based few-shot talking head synthesis method, which can rapidly generalize to an unseen identity with few training data.</p>
            </td>
          </tr>


		
	<tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/sdnerf.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>SD-NeRF: Towards Lifelike Talking Head Animation via Spatially-adaptive Dual-driven NeRFs</papertitle>
              <br>
			  <strong>Shuai Shen</strong>, Wanhua Li, Xiaoke Huang, Zheng Zhu, Jie Zhou, and Jiwen Lu
              <br>
              <em>IEEE Transactions on Multimedia (TMM)</em>, 2023
			  <br>
              <a href="https://ieeexplore.ieee.org/abstract/document/10229247">[arxiv]</a> 
	      <a href="https://cloud.tsinghua.edu.cn/f/7ebd663951e5403da4a5/">[Video]</a> 
              <br>
              <p> A NeRF-based few-shot talking head synthesis method, which can rapidly generalize to an unseen identity with few training data.</p>
            </td>
          </tr>
		

		
	<tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/clip_cluster.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>CLIP-Cluster: CLIP-Guided Attribute Hallucination for Face Clustering</papertitle>
              <br>
			  <strong>Shuai Shen</strong>, Wanhua Li, Xiaobing Wang, Dafeng Zhang, Zhezhu Jin, Jie Zhou, and Jiwen Lu
              <br>
              <em>Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</em>, 2023
			  <br>
              <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Shen_CLIP-Cluster_CLIP-Guided_Attribute_Hallucination_for_Face_Clustering_ICCV_2023_paper.pdf">[PDF]</a> 
              <br>
              <p> A NeRF-based few-shot talking head synthesis method, which can rapidly generalize to an unseen identity with few training data.</p>
            </td>
          </tr>


		
	<tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/difftalk.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>DiffTalk: Crafting Diffusion Models for Generalized Audio-Driven Portraits Animation</papertitle>
              <br>
			  <strong>Shuai Shen</strong>, Wenliang Zhao, Zibin Meng, Wanhua Li, Zheng Zhu, Jie Zhou, and Jiwen Lu
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2023
			  <br>
              <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Shen_DiffTalk_Crafting_Diffusion_Models_for_Generalized_Audio-Driven_Portraits_Animation_CVPR_2023_paper.pdf">[PDF]</a> 
	      <a href="https://cloud.tsinghua.edu.cn/f/e13f5aad2f4c4f898ae7/">[Video]</a> 
              <a href="https://github.com/sstzal/DiffTalk">[Code]</a>
              <a href="https://sstzal.github.io/DiffTalk/">[Project]</a>
              <br>
              <p> A NeRF-based few-shot talking head synthesis method, which can rapidly generalize to an unseen identity with few training data.</p>
            </td>
          </tr>

		

	<tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/DFRF.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Learning Dynamic Facial Radiance Fields for Few-Shot Talking Head Synthesis</papertitle>
              <br>
			  <strong>Shuai Shen</strong>, Wanhua Li, Zheng Zhu, Yueqi Duan, Jie Zhou, and Jiwen Lu
              <br>
              <em>European Conference on Computer Vision (ECCV)</em>, 2022
			  <br>
              <a href="https://arxiv.org/abs/2207.11770">[arxiv]</a> 
	      <a href="https://www.youtube.com/watch?v=F6fkVNk9bBw">[Video]</a> 
              <a href="https://github.com/sstzal/DFRF">[Code]</a>
              <a href="https://sstzal.github.io/DFRF/">[Project]</a>
              <br>
              <p> A NeRF-based few-shot talking head synthesis method, which can rapidly generalize to an unseen identity with few training data.</p>
            </td>
          </tr>


		
	<tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/STAR_FC.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Structure-Aware Face Clustering on a Large-Scale Graph with 10^7 Nodes</papertitle>
              <br>
			  <strong>Shuai Shen</strong>, Wanhua Li, Zheng Zhu, Guan Huang, Dalong Du, Jiwen Lu, and Jie Zhou
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2021
			  <br>
              <a href="https://arxiv.org/abs/2103.13225">[arxiv]</a> 
	      <a href="https://www.youtube.com/watch?v=VwAomM3wk6k">[Video]</a> 
              <a href="https://github.com/sstzal/STAR-FC">[Code]</a>
              <a href="https://sstzal.github.io/STAR-FC/">[Project]</a>
              <br>
              <p> It is the first face clustering method to train on very large-scale graph with 20M nodes, and achieve superior inference results on 12M testing data.</p>
            </td>
          </tr>

		
            </p>
          </td>
        </tr>
      </tbody></table>
		
		<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Professional Activities</heading>
            <p>
              <li style="margin: 5px;" >
                <b>Reviewer,</b> IEEE International Conference on Multimedia and Expo (ICME), 2021.
              </li>
             <li style="margin: 5px;" >
                <b>Reviewer,</b> European Conference on Computer Vision (ECCV), 2022.
              </li>
             <li style="margin: 5px;" >
                <b>Reviewer,</b> IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI).
              </li>
             <li style="margin: 5px;" >
                <b>Reviewer,</b> IEEE Transactions on Image Processing (TIP).
              </li>
            </p>
          </td>
        </tr>
      </tbody></table>
	  
	  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <a href="https://nvlabs.github.io/face-vid2vid/">Website Template</a>
              </p>
            </td>
          </tr>
        </tbody></table>
       
      </td>
    </tr>
  </table>
</body>

</html>
