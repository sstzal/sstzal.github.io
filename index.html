<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Shuai Shen</title>
  
  <meta name="author" content="Shuai Shen">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Shuai Shen</name>
              </p>
              <p>I am a fifth-year Ph.D. student in the Department of Automation at Tsinghua University, advised by Prof. <a href="https://scholar.google.com/citations?user=TN8uDQoAAAAJ&hl=zh-CN">Jiwen Lu</a> and Prof. <a href="https://scholar.google.com/citations?user=6a79aPwAAAAJ&hl=zh-CN">Jie Zhou</a>.
		      Prior to that, I received my B.S. degree in the Department of Automation at Tsinghua University in 2019. 
			  </p>
			  <p>My research interests lie in computer vision and deep learning, particularly in <b>face clustering and face synthesis</b>.
              </p>
              <p><strong>I anticipate graduating in June 2024, and now I am looking for a postdoctoral position. If you are interested in my research, feel free to drop me an e-mail shens19[AT]mails.tsinghua.edu.cn.</strong>
              </p>
              <p style="text-align:center">
                <a href="mailto:shens19@mails.tsinghua.edu.cn"> Email </a> &nbsp/&nbsp  
                <a href="https://github.com/sstzal"> GitHub </a> &nbsp/&nbsp  
		<a gref="https://scholar.google.com/citations?user=0WpC3DsAAAAJ&hl=zh-CN"> Google Scholar </a>
              </p>
            </td>
            <td style="padding:2.5%;width:30%;max-width:30%">
              <a href="images/shenshuai1.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/shenshuai_circle.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
		
		
		<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>News</heading>
            <p>
	      <li style="margin: 5px;">
                <b>2023-10:</b> I get the Friends of Tsinghua - Suzhou Talent Scholarship <b>(top 5%)</b></a>.
              </li>
	      <li style="margin: 5px;">
                <b>2023-08:</b> One paper is accepted to <a href="https://signalprocessingsociety.org/publications-resources/ieee-transactions-multimedia">TMM</a>.
              </li>
	      <li style="margin: 5px;">
                <b>2023-07:</b> One paper is accepted to <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">TPAMI</a>.
              </li>
	      <li style="margin: 5px;">
                <b>2023-07:</b> One paper is accepted to <a href="https://iccv2023.thecvf.com/">ICCV 2023</a>.
              </li>
	      <li style="margin: 5px;">
                <b>2023-03:</b> One paper is accepted to <a href="http://cvpr2023.thecvf.com/">CVPR 2023</a>.
              </li>
	      <li style="margin: 5px;">
                <b>2022-10:</b> I get the Huiyan Talent Second Prize Scholarship of Tsinghua <b>(top 10%)</b></a>.
              </li>
	      <li style="margin: 5px;">
                <b>2022-07:</b> One paper is accepted to <a href="https://eccv2022.ecva.net/">ECCV 2022</a>.
              </li> 
	      <li style="margin: 5px;">
                <b>2021-03:</b> One paper is accepted to <a href="http://cvpr2021.thecvf.com/">CVPR 2021</a>.
              </li>
            </p>
          </td>
        </tr>
      </tbody></table>
	  
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
			  <p></p>
            </td>
          </tr>
        </tbody></table>

	(* indicates equal contribution.)
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
	<tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/star++.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>STAR-FC: Structure-Aware Face Clustering on Ultra-Large-Scale Graphs</papertitle>
              <br>
		<strong>Shuai Shen</strong>, Wanhua Li, Zheng Zhu, Jie Zhou, and Jiwen Lu
              <br>
              <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</em>, 2023
			  <br>
              <a href="https://ieeexplore.ieee.org/abstract/document/10195951">[PDF]</a> 
              <a href="https://github.com/sstzal/STAR-FC">[Code]</a>
              <br>
              <p>We develop a hierarchical GCN training paradigm and the adaptive Node Intimacy strategy for adaptive neighbor interaction.</p><br><br>
            </td>
          </tr>
	
	<tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/sdnerf.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>SD-NeRF: Towards Lifelike Talking Head Animation via Spatially-adaptive Dual-driven NeRFs</papertitle>
              <br>
		<strong>Shuai Shen*</strong>, Wanhua Li*, Xiaoke Huang*, Zheng Zhu, Jie Zhou, and Jiwen Lu
              <br>
              <em>IEEE Transactions on Multimedia (TMM)</em>, 2023
			  <br>
              <a href="https://ieeexplore.ieee.org/abstract/document/10229247">[PDF]</a> 
	      <a href="https://cloud.tsinghua.edu.cn/f/7ebd663951e5403da4a5/">[Video]</a> 
              <br>
              <p> We propose a Spatially-adaptive Dual-driven NeRF (SD-NeRF) to model the spontaneous facial motions with audio-to-lip mapping into the facial radiance field for vivid talking head animation.</p><br><br>
            </td>
          </tr>
		
	<tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/clip_cluster.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>CLIP-Cluster: CLIP-Guided Attribute Hallucination for Face Clustering</papertitle>
              <br>
		<strong>Shuai Shen</strong>, Wanhua Li, Xiaobing Wang, Dafeng Zhang, Zhezhu Jin, Jie Zhou, and Jiwen Lu
              <br>
              <em>Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</em>, 2023
			  <br>
              <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Shen_CLIP-Cluster_CLIP-Guided_Attribute_Hallucination_for_Face_Clustering_ICCV_2023_paper.pdf">[PDF]</a> 
              <br>
              <p>We propose an attribute hallucination framework named CLIP-Cluster to narrow the intraclass variance caused by different face attributes for face clustering.</p><br><br>
            </td>
          </tr>
	
	<tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/difftalk.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>DiffTalk: Crafting Diffusion Models for Generalized Audio-Driven Portraits Animation</papertitle>
              <br>
		<strong>Shuai Shen</strong>, Wenliang Zhao, Zibin Meng, Wanhua Li, Zheng Zhu, Jie Zhou, and Jiwen Lu
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2023
			  <br>
              <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Shen_DiffTalk_Crafting_Diffusion_Models_for_Generalized_Audio-Driven_Portraits_Animation_CVPR_2023_paper.pdf">[PDF]</a> 
	      <a href="https://cloud.tsinghua.edu.cn/f/e13f5aad2f4c4f898ae7/">[Video]</a> 
              <a href="https://github.com/sstzal/DiffTalk">[Code]</a>
              <a href="https://sstzal.github.io/DiffTalk/">[Project]</a>
              <br>
              <p> We model the talking head synthesis as an audio-driven temporally coherent denoising process based on the Diffusion Model, which can be generalized across different identities.</p><br><br>
            </td>
          </tr>

	<tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/DFRF.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Learning Dynamic Facial Radiance Fields for Few-Shot Talking Head Synthesis</papertitle>
              <br>
		<strong>Shuai Shen</strong>, Wanhua Li, Zheng Zhu, Yueqi Duan, Jie Zhou, and Jiwen Lu
              <br>
              <em>European Conference on Computer Vision (ECCV)</em>, 2022
			  <br>
              <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136720657.pdf">[PDF]</a> 
	      <a href="https://www.youtube.com/watch?v=F6fkVNk9bBw">[Video]</a> 
              <a href="https://github.com/sstzal/DFRF">[Code]</a>
              <a href="https://sstzal.github.io/DFRF/">[Project]</a>
              <br>
              <p> A NeRF-based few-shot talking head synthesis method, which can rapidly generalize to an unseen identity with few training data.</p><br><br>
            </td>
          </tr>
		
	<tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/STAR_FC.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Structure-Aware Face Clustering on a Large-Scale Graph with 10^7 Nodes</papertitle>
              <br>
		<strong>Shuai Shen</strong>, Wanhua Li, Zheng Zhu, Guan Huang, Dalong Du, Jiwen Lu, and Jie Zhou
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2021
			  <br>
              <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Shen_Structure-Aware_Face_Clustering_on_a_Large-Scale_Graph_With_107_Nodes_CVPR_2021_paper.pdf">[PDF]</a> 
	      <a href="https://www.youtube.com/watch?v=VwAomM3wk6k">[Video]</a> 
              <a href="https://github.com/sstzal/STAR-FC">[Code]</a>
              <a href="https://sstzal.github.io/STAR-FC/">[Project]</a>
              <br>
              <p> It is the first face clustering method to train on very large-scale graph with 20M nodes, and achieve superior inference results on 12M testing data.</p><br><br>
            </td>
          </tr>
            </p>
          </td>
        </tr>
      </tbody></table>


		<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Honors and Awards</heading>
            <p>
              <li style="margin: 5px;" >
                Friends of Tsinghua - Suzhou Talent Scholarship <b>(top 5%)</b>, 2023.
              </li>
             <li style="margin: 5px;" >
                Huiyan Talent Second Prize Scholarship of Tsinghua <b>(top 10%)</b>, 2022.
              </li>
            </p>
          </td>
        </tr>
      </tbody></table>

	
		<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Professional Activities</heading>
            <p>
              <li style="margin: 5px;" >
                <b>Reviewer,</b> IEEE International Conference on Multimedia and Expo (ICME), 2021.
              </li>
             <li style="margin: 5px;" >
                <b>Reviewer,</b> European Conference on Computer Vision (ECCV), 2022.
              </li>
             <li style="margin: 5px;" >
                <b>Reviewer,</b> IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI).
              </li>
             <li style="margin: 5px;" >
                <b>Reviewer,</b> IEEE Transactions on Image Processing (TIP).
              </li>
             <li style="margin: 5px;" >
                <b>Reviewer,</b>  IEEE Transactions on Information Forensics and Security (TIFS).
              </li>
             <li style="margin: 5px;" >
                <b>Reviewer,</b> IEEE Transactions on Multimedia (TMM).
              </li>
             <li style="margin: 5px;" >
                <b>Reviewer,</b> IEEE Transactions on Circuits and Systems for Video Technology (TCSVT).
              </li>
             <li style="margin: 5px;" >
                <b>Reviewer,</b> IEEE Transactions on Biometrics, Behavior, and Identity Science (TBIOM).
              </li>
            </p>
          </td>
        </tr>
      </tbody></table>

	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Teaching Assistant</heading>
            <p>
              <li style="margin: 5px;" >
                TA Numerical Analysis and Algorithm, Tsinghua University, 2020, 2021.
              </li>
             <li style="margin: 5px;" >
                TA Analog Electronic Technology Foundation, Tsinghua University, 2020, 2021.
              </li>
            </p>
          </td>
        </tr>
      </tbody></table>

	
	  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <a href="https://nvlabs.github.io/face-vid2vid/">Website Template</a>
              </p>
            </td>
          </tr>
        </tbody></table>
       
      </td>
    </tr>
  </table>
</body>

</html>
